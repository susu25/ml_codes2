{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "vietnamese-yugoslavia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1942ca3d6ec64c5193fe9df379c33695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b3fc48cffa43679fae57a7077a957b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e568d1ca3ad4739b9789eae4c8597e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a1fa20524f489ab89e13c3fea8b388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\torch\\csrc\\utils\\tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms # 注意transforms是torchvision里面的工具，主要是为图像开发\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),  # 转变成pytorch类型的tensor，针对图像进行转变，把载入的图像转变成Pytorch格式的tensor，结果为NCHW\n",
    "    transforms.Normalize((0.5,), (0.5,))]) # 标准化操作\n",
    "\n",
    "# datasets\n",
    "trainset = torchvision.datasets.FashionMNIST('./data',# 下载“训练集”/“测试集”，并转变数据形式(对图片格式进行转变)\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST('./data',  \n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)\n",
    "\n",
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)  # 这里面有一些讲究，尤其是多进程相关的，回过头来可以再看\n",
    "\n",
    "# constant for classes\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:         \n",
    "        img = img.mean(dim=0) # 其实就是一种数据维度的压缩，可以替换为img = img.squeeze(0)\n",
    "    img = img / 2 + 0.5     # unnormalize 反归一化，反向操作\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0))) # 转置回去，这是由于pytorch tensor和pil数据的内部维度排列有些差异"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "parliamentary-central",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):  # 继承nn.Module模块\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # 这个虽然pool只是定义了一次，但会用到多次\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "secondary-seattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() #结合了softmax和negative log loss\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afraid-salem",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('my_experiment/fashion_mnist_experiment') # 创建一个folder存储需要记录的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "authentic-satellite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)      # 通过使用函数iter()，将返回一个iterator迭代器（可以使用.__next__()的对象）\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images) # 定义网格图片，网格化显示a batch of images.\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True) # 我们的数据是单通道图片\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image('four_fashion_mnist_images', img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "union-joining",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net, images) # net是我们上边构建的模型class，images是输出的数据\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "designing-smooth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# Adding a “Projector” to TensorBoard\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile # 解决pytorch和tensorflow同时存在调用tensorboard是api冲突\n",
    "\n",
    "# helper function\n",
    "def select_n_random(data, labels, n=100):\n",
    "    '''\n",
    "    Selects n random datapoints and their corresponding labels from a dataset\n",
    "    '''\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data)) # Returns a random permutation of integers from ``0`` to ``n - 1``.\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# select random images and their target indices\n",
    "images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "\n",
    "# get the class labels for each image\n",
    "class_labels = [classes[lab] for lab in labels]\n",
    "\n",
    "# log embeddings\n",
    "features = images.view(-1, 28 * 28)\n",
    "writer.add_embedding(features,\n",
    "                    metadata=class_labels, # metadata:描述数据的数据就是元数据；这里就是类型标签\n",
    "                    label_img=images.unsqueeze(1)) # 在维度1位置插入一个size为1的维度，相当于多包了一层。扩展成四个维度NCHW，之前是NHW三个维度，而label_img要求NCHW四个维度\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "short-compact",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def images_to_probs(net, images):\n",
    "   '''\n",
    "   Generates predictions and corresponding probabilities from a trained\n",
    "   network and a list of images\n",
    "   '''\n",
    "   output = net(images)\n",
    "   # convert output probabilities to predicted class\n",
    "   _, preds_tensor = torch.max(output, 1)\n",
    "   preds = np.squeeze(preds_tensor.numpy())\n",
    "   return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)] # 返回预测结果及概率\n",
    "   # .item()返回的是一个标量，这个标量来源于只含一个数的tensor\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "   '''\n",
    "   Generates matplotlib Figure using a trained network, along with images\n",
    "   and labels from a batch, that shows the network's top prediction along\n",
    "   with its probability, alongside the actual label, coloring this\n",
    "   information based on whether the prediction was correct or not.\n",
    "   Uses the \"images_to_probs\" function.\n",
    "   '''\n",
    "   preds, probs = images_to_probs(net, images)\n",
    "   # plot the images in the batch, along with predicted and true labels\n",
    "   fig = plt.figure(figsize=(10, 10))\n",
    "   for idx in np.arange(4):\n",
    "       ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "       matplotlib_imshow(images[idx], one_channel=True)   # 注意该函数是在当前的子图环境中绘图的\n",
    "       ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "           classes[preds[idx]],\n",
    "           probs[idx] * 100.0,\n",
    "           classes[labels[idx]]),\n",
    "                   color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "   return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "speaking-month",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step() # 这一步已经包含torch.no_grad()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss_again',          \n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',   # 增加一些图到writer里\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + i)  # 全局步的记录\n",
    "            #请注意：add_figure方法里面的第二个位置参数的参数名是figure，他要求传入的object是\n",
    "            # matplotlib.pyplot.figure or list of figures: Figure or a list of figures\n",
    "            # 该段代码跑完后，notebook里面其实是没有任何figure显示，这是为何呢？我猜是\n",
    "            # writer.add_figure自动将其关闭了\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "spatial-switch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. gets the probability predictions in a test_size x num_classes Tensor\n",
    "# 2. gets the preds in a test_size Tensor\n",
    "# takes ~10 seconds to run\n",
    "class_probs = []\n",
    "class_preds = []\n",
    "gt_labels = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "#         print(images.shape,labels.shape)\n",
    "        output = net(images)\n",
    "        class_probs_batch = [F.softmax(el, dim=0) for el in output]  # 这里返回来的是4x10的tensor\n",
    "        _, class_preds_batch = torch.max(output, 1) \n",
    "#         print(class_preds_batch)\n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_preds.append(class_preds_batch)\n",
    "        gt_labels.append(labels)\n",
    "        \n",
    "# 每一次stack完后，会产生一个4x1x10的返回结果；在cat之前，是一个size为(n/4,4,1,10)的sequence，经过cat后，变成了一个(n,1,10)的tensor\n",
    "# 在送进tensor.cat前，必须是一个sequence，或者是一个可迭代对象iterable。本质上我们是想把诸如a、b、c这样的tensor进行cat，只不过\n",
    "# 输入的时候必须把他们装到一个可迭代对象中，这样函数才能遍历,这同样也是torch.stack的机制\n",
    "test_probs = torch.cat([torch.stack(batch) for batch in class_probs]) \n",
    "test_preds = torch.cat(class_preds) # 输出结果为(n,1)的tensor\n",
    "gt_labels = torch.cat(gt_labels)\n",
    "# helper function\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, gt_labels, global_step=0):\n",
    "    '''\n",
    "    Takes in a \"class_index\" from 0 to 9 and plots the corresponding\n",
    "    precision-recall curve\n",
    "    '''\n",
    "#     tensorboard_preds = tensorboard_preds == class_index # 这行代码明显是错的，不符合precision-recall curve的定义\n",
    "    gt_labels = gt_labels == class_index                 # 这行是正确的写法\n",
    "    \n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(classes[class_index],\n",
    "                        gt_labels,\n",
    "                        tensorboard_probs,\n",
    "                        global_step=global_step)\n",
    "    writer.close()\n",
    "# np.random.randint\n",
    "# plot all the pr curves\n",
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, test_probs, gt_labels, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-forward",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
