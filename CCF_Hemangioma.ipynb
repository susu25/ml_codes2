{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "preliminary-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "electronic-mountain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Data\\CCF_Data\\Hemangioma\n",
      "E:\\Data\\CCF_Data\\Hemangioma\\.checkpoint\n",
      "E:\\Data\\CCF_Data\\Hemangioma\\Log\n",
      "E:\\Data\\CCF_Data\\Hemangioma\\test\n",
      "E:\\Data\\CCF_Data\\Hemangioma\\train\n",
      "E:\\Data\\CCF_Data\\Hemangioma\\train\\img\n",
      "E:\\Data\\CCF_Data\\Hemangioma\\train\\mask\n",
      "E:\\Data\\CCF_Data\\Hemangioma\\工具类\n"
     ]
    }
   ],
   "source": [
    "# root_path = 'E:\\Data\\CCF_Data\\Hemangioma'\n",
    "\n",
    "# for dirname, _, filenames in os.walk(root_path):\n",
    "#     print(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "electrical-blame",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 440, 3)\n",
      "(1080, 1920, 3)\n"
     ]
    }
   ],
   "source": [
    "# import cv2\n",
    "# img = cv2.imread('E:\\\\Data\\\\CCF_Data\\\\Hemangioma\\\\train\\\\img\\\\20.png')\n",
    "# print(img.shape)\n",
    "# img = cv2.imread('E:\\\\Data\\\\CCF_Data\\\\Hemangioma\\\\train\\\\mask\\\\20.png')\n",
    "# print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "latter-mixture",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "import PIL.Image as Image\n",
    "import os\n",
    "\n",
    "\n",
    "def make_dataset(root):\n",
    "    imgs = []\n",
    "    n = len(os.listdir(root)) // 2\n",
    "    for i in range(n):\n",
    "        img = os.path.join(root, \"%03d.png\" % i)\n",
    "        mask = os.path.join(root, \"%03d_mask.png\" % i)\n",
    "        imgs.append((img, mask))\n",
    "    return imgs\n",
    "\n",
    "\n",
    "class LiverDataset(data.Dataset):\n",
    "    def __init__(self, root, transform=None, target_transform=None):\n",
    "        imgs = make_dataset(root)\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x_path, y_path = self.imgs[index]\n",
    "        img_x = Image.open(x_path)\n",
    "        img_y = Image.open(y_path)\n",
    "        if self.transform is not None:\n",
    "            img_x = self.transform(img_x)\n",
    "        if self.target_transform is not None:\n",
    "            img_y = self.target_transform(img_y)\n",
    "        return img_x, img_y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sized-artwork",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch import autograd\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.conv(input)\n",
    "\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(Unet, self).__init__()\n",
    "\n",
    "        self.conv1 = DoubleConv(in_ch, 64)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = DoubleConv(64, 128)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.conv3 = DoubleConv(128, 256)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.conv4 = DoubleConv(256, 512)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "        self.conv5 = DoubleConv(512, 1024)\n",
    "        self.up6 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n",
    "        self.conv6 = DoubleConv(1024, 512)\n",
    "        self.up7 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "        self.conv7 = DoubleConv(512, 256)\n",
    "        self.up8 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.conv8 = DoubleConv(256, 128)\n",
    "        self.up9 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.conv9 = DoubleConv(128, 64)\n",
    "        self.conv10 = nn.Conv2d(64, out_ch, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        c1 = self.conv1(x)\n",
    "        p1 = self.pool1(c1)\n",
    "        c2 = self.conv2(p1)\n",
    "        p2 = self.pool2(c2)\n",
    "        c3 = self.conv3(p2)\n",
    "        p3 = self.pool3(c3)\n",
    "        c4 = self.conv4(p3)\n",
    "        p4 = self.pool4(c4)\n",
    "        c5 = self.conv5(p4)\n",
    "        up_6 = self.up6(c5)\n",
    "        merge6 = torch.cat([up_6, c4], dim=1)\n",
    "        c6 = self.conv6(merge6)\n",
    "        up_7 = self.up7(c6)\n",
    "        merge7 = torch.cat([up_7, c3], dim=1)\n",
    "        c7 = self.conv7(merge7)\n",
    "        up_8 = self.up8(c7)\n",
    "        merge8 = torch.cat([up_8, c2], dim=1)\n",
    "        c8 = self.conv8(merge8)\n",
    "        up_9 = self.up9(c8)\n",
    "        merge9 = torch.cat([up_9, c1], dim=1)\n",
    "        c9 = self.conv9(merge9)\n",
    "        c10 = self.conv10(c9)\n",
    "        out = nn.Sigmoid()(c10)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "sufficient-operation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def imshow(inp, title=None):\n",
    "#     \"\"\"Imshow for Tensor.\"\"\"\n",
    "#     inp = inp.numpy().transpose((1, 2, 0))\n",
    "#     mean = np.array([0.485, 0.456, 0.406])\n",
    "#     std = np.array([0.229, 0.224, 0.225])\n",
    "#     inp = std * inp + mean\n",
    "#     inp = np.clip(inp, 0, 1)\n",
    "#     plt.imshow(inp)\n",
    "#     if title is not None:\n",
    "#         plt.title(title)\n",
    "#     plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "colored-clear",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import autograd, optim\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "# 是否使用cuda\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 把多个步骤整合到一起, channel=（channel-mean）/std, 因为是分别对三个通道处理\n",
    "x_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),  # -> [0,1]\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  # ->[-1,1]\n",
    "])\n",
    "\n",
    "# mask只需要转换为tensor\n",
    "y_transforms = transforms.ToTensor()\n",
    "\n",
    "def train_model(model, criterion, optimizer, dataload, num_epochs=20):\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        dt_size = len(dataload.dataset)\n",
    "        epoch_loss = 0\n",
    "        step = 0\n",
    "        for x, y in dataload:\n",
    "            step += 1\n",
    "            inputs = x.to(device)\n",
    "            labels = y.to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            print(\"%d/%d,train_loss:%0.3f\" % (step, (dt_size - 1) // dataload.batch_size + 1, loss.item()))\n",
    "        print(\"epoch %d loss:%0.3f\" % (epoch, epoch_loss))\n",
    "    torch.save(model.state_dict(), 'E:\\\\BaiduNetdiskDownload\\\\u_net_liver-master\\\\checkpoint\\\\weights_%d.pth' % epoch)\n",
    "    return model\n",
    "\n",
    "\n",
    "# 训练模型\n",
    "def train(batch_size):\n",
    "    model = Unet(3, 1).to(device)\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    liver_dataset = LiverDataset(\"E:\\\\BaiduNetdiskDownload\\\\u_net_liver-master\\\\data\\\\train\", transform=x_transforms, target_transform=y_transforms)\n",
    "    dataloaders = DataLoader(liver_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    train_model(model, criterion, optimizer, dataloaders)\n",
    "\n",
    "\n",
    "# 显示模型的输出结果\n",
    "def test(model_dir):\n",
    "    model = Unet(3, 1)\n",
    "    model.load_state_dict(torch.load(model_dir, map_location='cpu'))\n",
    "    liver_dataset = LiverDataset(\"E:\\\\BaiduNetdiskDownload\\\\u_net_liver-master\\\\data\\\\val\", transform=x_transforms, target_transform=y_transforms)\n",
    "    dataloaders = DataLoader(liver_dataset, batch_size=1)\n",
    "    model.eval()\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.ion()\n",
    "    with torch.no_grad():\n",
    "        for x, _ in dataloaders:\n",
    "            y = model(x)\n",
    "            img_y = torch.squeeze(y).numpy()\n",
    "            plt.imshow(img_y)\n",
    "            plt.pause(0.1)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "forward-ballot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "1/200,train_loss:0.680\n",
      "2/200,train_loss:0.594\n",
      "3/200,train_loss:0.511\n",
      "4/200,train_loss:0.455\n",
      "5/200,train_loss:0.435\n",
      "6/200,train_loss:0.385\n",
      "7/200,train_loss:0.377\n",
      "8/200,train_loss:0.408\n",
      "9/200,train_loss:0.369\n",
      "10/200,train_loss:0.342\n",
      "11/200,train_loss:0.387\n",
      "12/200,train_loss:0.367\n",
      "13/200,train_loss:0.309\n",
      "14/200,train_loss:0.306\n",
      "15/200,train_loss:0.306\n",
      "16/200,train_loss:0.291\n",
      "17/200,train_loss:0.289\n",
      "18/200,train_loss:0.270\n",
      "19/200,train_loss:0.267\n",
      "20/200,train_loss:0.285\n",
      "21/200,train_loss:0.247\n",
      "22/200,train_loss:0.267\n",
      "23/200,train_loss:0.245\n",
      "24/200,train_loss:0.247\n",
      "25/200,train_loss:0.247\n",
      "26/200,train_loss:0.230\n",
      "27/200,train_loss:0.250\n",
      "28/200,train_loss:0.212\n",
      "29/200,train_loss:0.207\n",
      "30/200,train_loss:0.272\n",
      "31/200,train_loss:0.198\n",
      "32/200,train_loss:0.200\n",
      "33/200,train_loss:0.238\n",
      "34/200,train_loss:0.271\n",
      "35/200,train_loss:0.195\n",
      "36/200,train_loss:0.201\n",
      "37/200,train_loss:0.202\n",
      "38/200,train_loss:0.189\n",
      "39/200,train_loss:0.180\n",
      "40/200,train_loss:0.200\n",
      "41/200,train_loss:0.215\n",
      "42/200,train_loss:0.176\n",
      "43/200,train_loss:0.173\n",
      "44/200,train_loss:0.198\n",
      "45/200,train_loss:0.153\n",
      "46/200,train_loss:0.158\n",
      "47/200,train_loss:0.151\n",
      "48/200,train_loss:0.154\n",
      "49/200,train_loss:0.148\n",
      "50/200,train_loss:0.175\n",
      "51/200,train_loss:0.185\n",
      "52/200,train_loss:0.173\n",
      "53/200,train_loss:0.187\n",
      "54/200,train_loss:0.166\n",
      "55/200,train_loss:0.157\n",
      "56/200,train_loss:0.141\n",
      "57/200,train_loss:0.129\n",
      "58/200,train_loss:0.137\n",
      "59/200,train_loss:0.154\n",
      "60/200,train_loss:0.155\n",
      "61/200,train_loss:0.128\n",
      "62/200,train_loss:0.174\n",
      "63/200,train_loss:0.121\n",
      "64/200,train_loss:0.122\n",
      "65/200,train_loss:0.143\n",
      "66/200,train_loss:0.132\n",
      "67/200,train_loss:0.124\n",
      "68/200,train_loss:0.120\n",
      "69/200,train_loss:0.121\n",
      "70/200,train_loss:0.107\n",
      "71/200,train_loss:0.133\n",
      "72/200,train_loss:0.103\n",
      "73/200,train_loss:0.103\n",
      "74/200,train_loss:0.137\n",
      "75/200,train_loss:0.115\n",
      "76/200,train_loss:0.099\n",
      "77/200,train_loss:0.108\n",
      "78/200,train_loss:0.099\n",
      "79/200,train_loss:0.120\n",
      "80/200,train_loss:0.099\n",
      "81/200,train_loss:0.094\n",
      "82/200,train_loss:0.099\n",
      "83/200,train_loss:0.091\n",
      "84/200,train_loss:0.090\n",
      "85/200,train_loss:0.109\n",
      "86/200,train_loss:0.099\n",
      "87/200,train_loss:0.085\n",
      "88/200,train_loss:0.088\n",
      "89/200,train_loss:0.095\n",
      "90/200,train_loss:0.087\n",
      "91/200,train_loss:0.077\n",
      "92/200,train_loss:0.087\n",
      "93/200,train_loss:0.081\n",
      "94/200,train_loss:0.117\n",
      "95/200,train_loss:0.076\n",
      "96/200,train_loss:0.106\n",
      "97/200,train_loss:0.080\n",
      "98/200,train_loss:0.077\n",
      "99/200,train_loss:0.076\n",
      "100/200,train_loss:0.071\n",
      "101/200,train_loss:0.083\n",
      "102/200,train_loss:0.087\n",
      "103/200,train_loss:0.079\n",
      "104/200,train_loss:0.072\n",
      "105/200,train_loss:0.089\n",
      "106/200,train_loss:0.091\n",
      "107/200,train_loss:0.074\n",
      "108/200,train_loss:0.071\n",
      "109/200,train_loss:0.073\n",
      "110/200,train_loss:0.096\n",
      "111/200,train_loss:0.091\n",
      "112/200,train_loss:0.084\n",
      "113/200,train_loss:0.117\n",
      "114/200,train_loss:0.068\n",
      "115/200,train_loss:0.082\n",
      "116/200,train_loss:0.081\n",
      "117/200,train_loss:0.067\n",
      "118/200,train_loss:0.069\n",
      "119/200,train_loss:0.071\n",
      "120/200,train_loss:0.087\n",
      "121/200,train_loss:0.065\n",
      "122/200,train_loss:0.065\n",
      "123/200,train_loss:0.085\n",
      "124/200,train_loss:0.093\n",
      "125/200,train_loss:0.062\n",
      "126/200,train_loss:0.065\n",
      "127/200,train_loss:0.065\n",
      "128/200,train_loss:0.073\n",
      "129/200,train_loss:0.085\n",
      "130/200,train_loss:0.064\n",
      "131/200,train_loss:0.061\n",
      "132/200,train_loss:0.064\n",
      "133/200,train_loss:0.056\n",
      "134/200,train_loss:0.053\n",
      "135/200,train_loss:0.055\n",
      "136/200,train_loss:0.106\n",
      "137/200,train_loss:0.079\n",
      "138/200,train_loss:0.066\n",
      "139/200,train_loss:0.056\n",
      "140/200,train_loss:0.087\n",
      "141/200,train_loss:0.055\n",
      "142/200,train_loss:0.059\n",
      "143/200,train_loss:0.065\n",
      "144/200,train_loss:0.086\n",
      "145/200,train_loss:0.051\n",
      "146/200,train_loss:0.063\n",
      "147/200,train_loss:0.063\n",
      "148/200,train_loss:0.047\n",
      "149/200,train_loss:0.054\n",
      "150/200,train_loss:0.089\n",
      "151/200,train_loss:0.049\n",
      "152/200,train_loss:0.068\n",
      "153/200,train_loss:0.048\n",
      "154/200,train_loss:0.046\n",
      "155/200,train_loss:0.058\n",
      "156/200,train_loss:0.063\n",
      "157/200,train_loss:0.050\n",
      "158/200,train_loss:0.060\n",
      "159/200,train_loss:0.047\n",
      "160/200,train_loss:0.070\n",
      "161/200,train_loss:0.099\n",
      "162/200,train_loss:0.055\n",
      "163/200,train_loss:0.048\n",
      "164/200,train_loss:0.053\n",
      "165/200,train_loss:0.060\n",
      "166/200,train_loss:0.056\n",
      "167/200,train_loss:0.053\n",
      "168/200,train_loss:0.052\n",
      "169/200,train_loss:0.064\n",
      "170/200,train_loss:0.042\n",
      "171/200,train_loss:0.046\n",
      "172/200,train_loss:0.096\n",
      "173/200,train_loss:0.044\n",
      "174/200,train_loss:0.048\n",
      "175/200,train_loss:0.064\n",
      "176/200,train_loss:0.038\n",
      "177/200,train_loss:0.094\n",
      "178/200,train_loss:0.047\n",
      "179/200,train_loss:0.074\n",
      "180/200,train_loss:0.064\n",
      "181/200,train_loss:0.065\n",
      "182/200,train_loss:0.042\n",
      "183/200,train_loss:0.073\n",
      "184/200,train_loss:0.049\n",
      "185/200,train_loss:0.054\n",
      "186/200,train_loss:0.060\n",
      "187/200,train_loss:0.074\n",
      "188/200,train_loss:0.058\n",
      "189/200,train_loss:0.050\n",
      "190/200,train_loss:0.068\n",
      "191/200,train_loss:0.073\n",
      "192/200,train_loss:0.046\n",
      "193/200,train_loss:0.041\n",
      "194/200,train_loss:0.043\n",
      "195/200,train_loss:0.075\n",
      "196/200,train_loss:0.040\n",
      "197/200,train_loss:0.078\n",
      "198/200,train_loss:0.040\n",
      "199/200,train_loss:0.042\n",
      "200/200,train_loss:0.090\n",
      "epoch 0 loss:26.196\n",
      "Epoch 1/19\n",
      "----------\n",
      "1/200,train_loss:0.054\n",
      "2/200,train_loss:0.033\n",
      "3/200,train_loss:0.087\n",
      "4/200,train_loss:0.054\n",
      "5/200,train_loss:0.053\n",
      "6/200,train_loss:0.055\n",
      "7/200,train_loss:0.064\n",
      "8/200,train_loss:0.045\n",
      "9/200,train_loss:0.039\n",
      "10/200,train_loss:0.038\n",
      "11/200,train_loss:0.037\n",
      "12/200,train_loss:0.040\n",
      "13/200,train_loss:0.052\n",
      "14/200,train_loss:0.047\n",
      "15/200,train_loss:0.032\n",
      "16/200,train_loss:0.041\n",
      "17/200,train_loss:0.039\n",
      "18/200,train_loss:0.042\n",
      "19/200,train_loss:0.034\n",
      "20/200,train_loss:0.034\n",
      "21/200,train_loss:0.052\n",
      "22/200,train_loss:0.043\n",
      "23/200,train_loss:0.044\n",
      "24/200,train_loss:0.048\n",
      "25/200,train_loss:0.031\n",
      "26/200,train_loss:0.033\n",
      "27/200,train_loss:0.034\n",
      "28/200,train_loss:0.030\n",
      "29/200,train_loss:0.041\n",
      "30/200,train_loss:0.039\n",
      "31/200,train_loss:0.051\n",
      "32/200,train_loss:0.037\n",
      "33/200,train_loss:0.032\n",
      "34/200,train_loss:0.039\n",
      "35/200,train_loss:0.059\n",
      "36/200,train_loss:0.040\n",
      "37/200,train_loss:0.033\n",
      "38/200,train_loss:0.039\n",
      "39/200,train_loss:0.075\n",
      "40/200,train_loss:0.042\n",
      "41/200,train_loss:0.035\n",
      "42/200,train_loss:0.089\n",
      "43/200,train_loss:0.033\n",
      "44/200,train_loss:0.026\n",
      "45/200,train_loss:0.037\n",
      "46/200,train_loss:0.030\n",
      "47/200,train_loss:0.045\n",
      "48/200,train_loss:0.048\n",
      "49/200,train_loss:0.037\n",
      "50/200,train_loss:0.038\n",
      "51/200,train_loss:0.053\n",
      "52/200,train_loss:0.044\n",
      "53/200,train_loss:0.038\n",
      "54/200,train_loss:0.033\n",
      "55/200,train_loss:0.031\n",
      "56/200,train_loss:0.032\n",
      "57/200,train_loss:0.032\n",
      "58/200,train_loss:0.027\n",
      "59/200,train_loss:0.027\n",
      "60/200,train_loss:0.036\n",
      "61/200,train_loss:0.027\n",
      "62/200,train_loss:0.044\n",
      "63/200,train_loss:0.064\n",
      "64/200,train_loss:0.038\n",
      "65/200,train_loss:0.036\n",
      "66/200,train_loss:0.028\n",
      "67/200,train_loss:0.032\n",
      "68/200,train_loss:0.026\n",
      "69/200,train_loss:0.036\n",
      "70/200,train_loss:0.034\n",
      "71/200,train_loss:0.047\n",
      "72/200,train_loss:0.025\n",
      "73/200,train_loss:0.033\n",
      "74/200,train_loss:0.022\n",
      "75/200,train_loss:0.048\n",
      "76/200,train_loss:0.046\n",
      "77/200,train_loss:0.042\n",
      "78/200,train_loss:0.024\n",
      "79/200,train_loss:0.035\n",
      "80/200,train_loss:0.037\n",
      "81/200,train_loss:0.031\n",
      "82/200,train_loss:0.035\n",
      "83/200,train_loss:0.031\n",
      "84/200,train_loss:0.069\n",
      "85/200,train_loss:0.025\n",
      "86/200,train_loss:0.029\n",
      "87/200,train_loss:0.051\n",
      "88/200,train_loss:0.027\n",
      "89/200,train_loss:0.032\n",
      "90/200,train_loss:0.027\n",
      "91/200,train_loss:0.033\n",
      "92/200,train_loss:0.027\n",
      "93/200,train_loss:0.047\n",
      "94/200,train_loss:0.023\n",
      "95/200,train_loss:0.043\n",
      "96/200,train_loss:0.030\n",
      "97/200,train_loss:0.059\n",
      "98/200,train_loss:0.046\n",
      "99/200,train_loss:0.036\n",
      "100/200,train_loss:0.074\n",
      "101/200,train_loss:0.032\n",
      "102/200,train_loss:0.020\n",
      "103/200,train_loss:0.025\n",
      "104/200,train_loss:0.047\n",
      "105/200,train_loss:0.042\n",
      "106/200,train_loss:0.029\n",
      "107/200,train_loss:0.031\n",
      "108/200,train_loss:0.038\n",
      "109/200,train_loss:0.071\n",
      "110/200,train_loss:0.029\n",
      "111/200,train_loss:0.041\n",
      "112/200,train_loss:0.054\n",
      "113/200,train_loss:0.047\n",
      "114/200,train_loss:0.087\n",
      "115/200,train_loss:0.034\n",
      "116/200,train_loss:0.032\n",
      "117/200,train_loss:0.044\n",
      "118/200,train_loss:0.047\n",
      "119/200,train_loss:0.043\n",
      "120/200,train_loss:0.036\n",
      "121/200,train_loss:0.032\n",
      "122/200,train_loss:0.031\n",
      "123/200,train_loss:0.030\n",
      "124/200,train_loss:0.041\n",
      "125/200,train_loss:0.055\n",
      "126/200,train_loss:0.033\n",
      "127/200,train_loss:0.035\n",
      "128/200,train_loss:0.067\n",
      "129/200,train_loss:0.032\n",
      "130/200,train_loss:0.027\n",
      "131/200,train_loss:0.057\n",
      "132/200,train_loss:0.035\n",
      "133/200,train_loss:0.053\n",
      "134/200,train_loss:0.034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/200,train_loss:0.051\n",
      "136/200,train_loss:0.042\n",
      "137/200,train_loss:0.035\n",
      "138/200,train_loss:0.035\n",
      "139/200,train_loss:0.028\n",
      "140/200,train_loss:0.028\n",
      "141/200,train_loss:0.032\n",
      "142/200,train_loss:0.033\n",
      "143/200,train_loss:0.048\n",
      "144/200,train_loss:0.031\n",
      "145/200,train_loss:0.023\n",
      "146/200,train_loss:0.022\n",
      "147/200,train_loss:0.041\n",
      "148/200,train_loss:0.027\n",
      "149/200,train_loss:0.043\n",
      "150/200,train_loss:0.026\n",
      "151/200,train_loss:0.027\n",
      "152/200,train_loss:0.036\n",
      "153/200,train_loss:0.025\n",
      "154/200,train_loss:0.048\n",
      "155/200,train_loss:0.022\n",
      "156/200,train_loss:0.027\n",
      "157/200,train_loss:0.022\n",
      "158/200,train_loss:0.022\n",
      "159/200,train_loss:0.019\n",
      "160/200,train_loss:0.026\n",
      "161/200,train_loss:0.027\n",
      "162/200,train_loss:0.018\n",
      "163/200,train_loss:0.033\n",
      "164/200,train_loss:0.025\n",
      "165/200,train_loss:0.023\n",
      "166/200,train_loss:0.041\n",
      "167/200,train_loss:0.028\n",
      "168/200,train_loss:0.030\n",
      "169/200,train_loss:0.019\n",
      "170/200,train_loss:0.027\n",
      "171/200,train_loss:0.021\n",
      "172/200,train_loss:0.025\n",
      "173/200,train_loss:0.032\n",
      "174/200,train_loss:0.034\n",
      "175/200,train_loss:0.039\n",
      "176/200,train_loss:0.024\n",
      "177/200,train_loss:0.039\n",
      "178/200,train_loss:0.032\n",
      "179/200,train_loss:0.020\n",
      "180/200,train_loss:0.032\n",
      "181/200,train_loss:0.028\n",
      "182/200,train_loss:0.036\n",
      "183/200,train_loss:0.035\n",
      "184/200,train_loss:0.031\n",
      "185/200,train_loss:0.024\n",
      "186/200,train_loss:0.035\n",
      "187/200,train_loss:0.020\n",
      "188/200,train_loss:0.029\n",
      "189/200,train_loss:0.025\n",
      "190/200,train_loss:0.024\n",
      "191/200,train_loss:0.018\n",
      "192/200,train_loss:0.023\n",
      "193/200,train_loss:0.018\n",
      "194/200,train_loss:0.016\n",
      "195/200,train_loss:0.023\n",
      "196/200,train_loss:0.029\n",
      "197/200,train_loss:0.024\n",
      "198/200,train_loss:0.032\n",
      "199/200,train_loss:0.015\n",
      "200/200,train_loss:0.019\n",
      "epoch 1 loss:7.311\n",
      "Epoch 2/19\n",
      "----------\n",
      "1/200,train_loss:0.021\n",
      "2/200,train_loss:0.021\n",
      "3/200,train_loss:0.013\n",
      "4/200,train_loss:0.017\n",
      "5/200,train_loss:0.047\n",
      "6/200,train_loss:0.014\n",
      "7/200,train_loss:0.023\n",
      "8/200,train_loss:0.020\n",
      "9/200,train_loss:0.030\n",
      "10/200,train_loss:0.022\n",
      "11/200,train_loss:0.038\n",
      "12/200,train_loss:0.018\n",
      "13/200,train_loss:0.015\n",
      "14/200,train_loss:0.021\n",
      "15/200,train_loss:0.018\n",
      "16/200,train_loss:0.024\n",
      "17/200,train_loss:0.020\n",
      "18/200,train_loss:0.023\n",
      "19/200,train_loss:0.022\n",
      "20/200,train_loss:0.022\n",
      "21/200,train_loss:0.018\n",
      "22/200,train_loss:0.020\n",
      "23/200,train_loss:0.025\n",
      "24/200,train_loss:0.028\n",
      "25/200,train_loss:0.036\n",
      "26/200,train_loss:0.019\n",
      "27/200,train_loss:0.013\n",
      "28/200,train_loss:0.020\n",
      "29/200,train_loss:0.021\n",
      "30/200,train_loss:0.027\n",
      "31/200,train_loss:0.030\n",
      "32/200,train_loss:0.021\n",
      "33/200,train_loss:0.017\n",
      "34/200,train_loss:0.018\n",
      "35/200,train_loss:0.022\n",
      "36/200,train_loss:0.031\n",
      "37/200,train_loss:0.039\n",
      "38/200,train_loss:0.023\n",
      "39/200,train_loss:0.023\n",
      "40/200,train_loss:0.021\n",
      "41/200,train_loss:0.021\n",
      "42/200,train_loss:0.019\n",
      "43/200,train_loss:0.028\n",
      "44/200,train_loss:0.026\n",
      "45/200,train_loss:0.026\n",
      "46/200,train_loss:0.021\n",
      "47/200,train_loss:0.020\n",
      "48/200,train_loss:0.033\n",
      "49/200,train_loss:0.015\n",
      "50/200,train_loss:0.016\n",
      "51/200,train_loss:0.015\n",
      "52/200,train_loss:0.019\n",
      "53/200,train_loss:0.014\n",
      "54/200,train_loss:0.019\n",
      "55/200,train_loss:0.018\n",
      "56/200,train_loss:0.021\n",
      "57/200,train_loss:0.017\n",
      "58/200,train_loss:0.017\n",
      "59/200,train_loss:0.025\n",
      "60/200,train_loss:0.022\n",
      "61/200,train_loss:0.032\n",
      "62/200,train_loss:0.016\n",
      "63/200,train_loss:0.040\n",
      "64/200,train_loss:0.023\n",
      "65/200,train_loss:0.025\n",
      "66/200,train_loss:0.021\n",
      "67/200,train_loss:0.021\n",
      "68/200,train_loss:0.021\n",
      "69/200,train_loss:0.025\n",
      "70/200,train_loss:0.016\n",
      "71/200,train_loss:0.038\n",
      "72/200,train_loss:0.021\n",
      "73/200,train_loss:0.014\n",
      "74/200,train_loss:0.015\n",
      "75/200,train_loss:0.028\n",
      "76/200,train_loss:0.023\n",
      "77/200,train_loss:0.011\n",
      "78/200,train_loss:0.016\n",
      "79/200,train_loss:0.013\n",
      "80/200,train_loss:0.012\n",
      "81/200,train_loss:0.042\n",
      "82/200,train_loss:0.028\n",
      "83/200,train_loss:0.016\n",
      "84/200,train_loss:0.015\n",
      "85/200,train_loss:0.018\n",
      "86/200,train_loss:0.018\n",
      "87/200,train_loss:0.016\n",
      "88/200,train_loss:0.030\n",
      "89/200,train_loss:0.018\n",
      "90/200,train_loss:0.029\n",
      "91/200,train_loss:0.019\n",
      "92/200,train_loss:0.012\n",
      "93/200,train_loss:0.041\n",
      "94/200,train_loss:0.014\n",
      "95/200,train_loss:0.016\n",
      "96/200,train_loss:0.017\n",
      "97/200,train_loss:0.021\n",
      "98/200,train_loss:0.020\n",
      "99/200,train_loss:0.017\n",
      "100/200,train_loss:0.021\n",
      "101/200,train_loss:0.012\n",
      "102/200,train_loss:0.017\n",
      "103/200,train_loss:0.019\n",
      "104/200,train_loss:0.014\n",
      "105/200,train_loss:0.026\n",
      "106/200,train_loss:0.012\n",
      "107/200,train_loss:0.011\n",
      "108/200,train_loss:0.014\n",
      "109/200,train_loss:0.036\n",
      "110/200,train_loss:0.020\n",
      "111/200,train_loss:0.012\n",
      "112/200,train_loss:0.012\n",
      "113/200,train_loss:0.010\n",
      "114/200,train_loss:0.031\n",
      "115/200,train_loss:0.022\n",
      "116/200,train_loss:0.019\n",
      "117/200,train_loss:0.029\n",
      "118/200,train_loss:0.017\n",
      "119/200,train_loss:0.012\n",
      "120/200,train_loss:0.014\n",
      "121/200,train_loss:0.040\n",
      "122/200,train_loss:0.012\n",
      "123/200,train_loss:0.020\n",
      "124/200,train_loss:0.037\n",
      "125/200,train_loss:0.024\n",
      "126/200,train_loss:0.019\n",
      "127/200,train_loss:0.023\n",
      "128/200,train_loss:0.015\n",
      "129/200,train_loss:0.034\n",
      "130/200,train_loss:0.028\n",
      "131/200,train_loss:0.016\n",
      "132/200,train_loss:0.028\n",
      "133/200,train_loss:0.025\n",
      "134/200,train_loss:0.019\n",
      "135/200,train_loss:0.022\n",
      "136/200,train_loss:0.015\n",
      "137/200,train_loss:0.026\n",
      "138/200,train_loss:0.023\n",
      "139/200,train_loss:0.014\n",
      "140/200,train_loss:0.013\n",
      "141/200,train_loss:0.030\n",
      "142/200,train_loss:0.025\n",
      "143/200,train_loss:0.018\n",
      "144/200,train_loss:0.016\n",
      "145/200,train_loss:0.013\n",
      "146/200,train_loss:0.018\n",
      "147/200,train_loss:0.019\n",
      "148/200,train_loss:0.021\n",
      "149/200,train_loss:0.035\n",
      "150/200,train_loss:0.015\n",
      "151/200,train_loss:0.019\n",
      "152/200,train_loss:0.018\n",
      "153/200,train_loss:0.017\n",
      "154/200,train_loss:0.017\n",
      "155/200,train_loss:0.032\n",
      "156/200,train_loss:0.023\n",
      "157/200,train_loss:0.012\n",
      "158/200,train_loss:0.020\n",
      "159/200,train_loss:0.017\n",
      "160/200,train_loss:0.015\n",
      "161/200,train_loss:0.017\n",
      "162/200,train_loss:0.017\n",
      "163/200,train_loss:0.014\n",
      "164/200,train_loss:0.020\n",
      "165/200,train_loss:0.013\n",
      "166/200,train_loss:0.019\n",
      "167/200,train_loss:0.013\n",
      "168/200,train_loss:0.015\n",
      "169/200,train_loss:0.009\n",
      "170/200,train_loss:0.008\n",
      "171/200,train_loss:0.018\n",
      "172/200,train_loss:0.016\n",
      "173/200,train_loss:0.015\n",
      "174/200,train_loss:0.021\n",
      "175/200,train_loss:0.018\n",
      "176/200,train_loss:0.016\n",
      "177/200,train_loss:0.013\n",
      "178/200,train_loss:0.026\n",
      "179/200,train_loss:0.025\n",
      "180/200,train_loss:0.013\n",
      "181/200,train_loss:0.014\n",
      "182/200,train_loss:0.020\n",
      "183/200,train_loss:0.012\n",
      "184/200,train_loss:0.014\n",
      "185/200,train_loss:0.013\n",
      "186/200,train_loss:0.042\n",
      "187/200,train_loss:0.012\n",
      "188/200,train_loss:0.016\n",
      "189/200,train_loss:0.016\n",
      "190/200,train_loss:0.018\n",
      "191/200,train_loss:0.023\n",
      "192/200,train_loss:0.014\n",
      "193/200,train_loss:0.016\n",
      "194/200,train_loss:0.013\n",
      "195/200,train_loss:0.017\n",
      "196/200,train_loss:0.013\n",
      "197/200,train_loss:0.023\n",
      "198/200,train_loss:0.015\n",
      "199/200,train_loss:0.018\n",
      "200/200,train_loss:0.017\n",
      "epoch 2 loss:4.073\n",
      "Epoch 3/19\n",
      "----------\n",
      "1/200,train_loss:0.017\n",
      "2/200,train_loss:0.019\n",
      "3/200,train_loss:0.018\n",
      "4/200,train_loss:0.015\n",
      "5/200,train_loss:0.013\n",
      "6/200,train_loss:0.017\n",
      "7/200,train_loss:0.017\n",
      "8/200,train_loss:0.011\n",
      "9/200,train_loss:0.025\n",
      "10/200,train_loss:0.010\n",
      "11/200,train_loss:0.009\n",
      "12/200,train_loss:0.026\n",
      "13/200,train_loss:0.008\n",
      "14/200,train_loss:0.017\n",
      "15/200,train_loss:0.015\n",
      "16/200,train_loss:0.013\n",
      "17/200,train_loss:0.034\n",
      "18/200,train_loss:0.014\n",
      "19/200,train_loss:0.017\n",
      "20/200,train_loss:0.015\n",
      "21/200,train_loss:0.012\n",
      "22/200,train_loss:0.014\n",
      "23/200,train_loss:0.015\n",
      "24/200,train_loss:0.015\n",
      "25/200,train_loss:0.015\n",
      "26/200,train_loss:0.016\n",
      "27/200,train_loss:0.015\n",
      "28/200,train_loss:0.015\n",
      "29/200,train_loss:0.012\n",
      "30/200,train_loss:0.015\n",
      "31/200,train_loss:0.010\n",
      "32/200,train_loss:0.020\n",
      "33/200,train_loss:0.015\n",
      "34/200,train_loss:0.009\n",
      "35/200,train_loss:0.008\n",
      "36/200,train_loss:0.007\n",
      "37/200,train_loss:0.012\n",
      "38/200,train_loss:0.014\n",
      "39/200,train_loss:0.015\n",
      "40/200,train_loss:0.019\n",
      "41/200,train_loss:0.021\n",
      "42/200,train_loss:0.017\n",
      "43/200,train_loss:0.013\n",
      "44/200,train_loss:0.013\n",
      "45/200,train_loss:0.025\n",
      "46/200,train_loss:0.014\n",
      "47/200,train_loss:0.007\n",
      "48/200,train_loss:0.012\n",
      "49/200,train_loss:0.032\n",
      "50/200,train_loss:0.011\n",
      "51/200,train_loss:0.012\n",
      "52/200,train_loss:0.039\n",
      "53/200,train_loss:0.011\n",
      "54/200,train_loss:0.018\n",
      "55/200,train_loss:0.019\n",
      "56/200,train_loss:0.023\n",
      "57/200,train_loss:0.020\n",
      "58/200,train_loss:0.019\n",
      "59/200,train_loss:0.014\n",
      "60/200,train_loss:0.015\n",
      "61/200,train_loss:0.016\n",
      "62/200,train_loss:0.027\n",
      "63/200,train_loss:0.014\n",
      "64/200,train_loss:0.015\n",
      "65/200,train_loss:0.012\n",
      "66/200,train_loss:0.020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/200,train_loss:0.017\n",
      "68/200,train_loss:0.016\n",
      "69/200,train_loss:0.018\n",
      "70/200,train_loss:0.021\n",
      "71/200,train_loss:0.040\n",
      "72/200,train_loss:0.070\n",
      "73/200,train_loss:0.031\n",
      "74/200,train_loss:0.021\n",
      "75/200,train_loss:0.031\n",
      "76/200,train_loss:0.032\n",
      "77/200,train_loss:0.045\n",
      "78/200,train_loss:0.051\n",
      "79/200,train_loss:0.027\n",
      "80/200,train_loss:0.022\n",
      "81/200,train_loss:0.057\n",
      "82/200,train_loss:0.022\n",
      "83/200,train_loss:0.015\n",
      "84/200,train_loss:0.050\n",
      "85/200,train_loss:0.040\n",
      "86/200,train_loss:0.018\n",
      "87/200,train_loss:0.022\n",
      "88/200,train_loss:0.028\n",
      "89/200,train_loss:0.032\n",
      "90/200,train_loss:0.018\n",
      "91/200,train_loss:0.040\n",
      "92/200,train_loss:0.013\n",
      "93/200,train_loss:0.015\n",
      "94/200,train_loss:0.016\n",
      "95/200,train_loss:0.038\n",
      "96/200,train_loss:0.016\n",
      "97/200,train_loss:0.026\n",
      "98/200,train_loss:0.014\n",
      "99/200,train_loss:0.018\n",
      "100/200,train_loss:0.016\n",
      "101/200,train_loss:0.016\n",
      "102/200,train_loss:0.024\n",
      "103/200,train_loss:0.032\n",
      "104/200,train_loss:0.017\n",
      "105/200,train_loss:0.025\n",
      "106/200,train_loss:0.014\n",
      "107/200,train_loss:0.013\n",
      "108/200,train_loss:0.016\n",
      "109/200,train_loss:0.014\n",
      "110/200,train_loss:0.018\n",
      "111/200,train_loss:0.016\n",
      "112/200,train_loss:0.015\n",
      "113/200,train_loss:0.033\n",
      "114/200,train_loss:0.039\n",
      "115/200,train_loss:0.015\n",
      "116/200,train_loss:0.019\n",
      "117/200,train_loss:0.023\n",
      "118/200,train_loss:0.017\n",
      "119/200,train_loss:0.020\n",
      "120/200,train_loss:0.020\n",
      "121/200,train_loss:0.009\n",
      "122/200,train_loss:0.014\n",
      "123/200,train_loss:0.012\n",
      "124/200,train_loss:0.022\n",
      "125/200,train_loss:0.025\n",
      "126/200,train_loss:0.011\n",
      "127/200,train_loss:0.016\n",
      "128/200,train_loss:0.023\n",
      "129/200,train_loss:0.024\n",
      "130/200,train_loss:0.015\n",
      "131/200,train_loss:0.025\n",
      "132/200,train_loss:0.018\n",
      "133/200,train_loss:0.018\n",
      "134/200,train_loss:0.021\n",
      "135/200,train_loss:0.017\n",
      "136/200,train_loss:0.016\n",
      "137/200,train_loss:0.017\n",
      "138/200,train_loss:0.010\n",
      "139/200,train_loss:0.015\n",
      "140/200,train_loss:0.011\n",
      "141/200,train_loss:0.019\n",
      "142/200,train_loss:0.014\n",
      "143/200,train_loss:0.018\n",
      "144/200,train_loss:0.031\n",
      "145/200,train_loss:0.031\n",
      "146/200,train_loss:0.012\n",
      "147/200,train_loss:0.013\n",
      "148/200,train_loss:0.016\n",
      "149/200,train_loss:0.017\n",
      "150/200,train_loss:0.014\n",
      "151/200,train_loss:0.013\n",
      "152/200,train_loss:0.017\n",
      "153/200,train_loss:0.011\n",
      "154/200,train_loss:0.014\n",
      "155/200,train_loss:0.018\n",
      "156/200,train_loss:0.009\n",
      "157/200,train_loss:0.013\n",
      "158/200,train_loss:0.024\n",
      "159/200,train_loss:0.018\n",
      "160/200,train_loss:0.015\n",
      "161/200,train_loss:0.007\n",
      "162/200,train_loss:0.013\n",
      "163/200,train_loss:0.010\n",
      "164/200,train_loss:0.019\n",
      "165/200,train_loss:0.011\n",
      "166/200,train_loss:0.009\n",
      "167/200,train_loss:0.030\n",
      "168/200,train_loss:0.020\n",
      "169/200,train_loss:0.012\n",
      "170/200,train_loss:0.016\n",
      "171/200,train_loss:0.031\n",
      "172/200,train_loss:0.011\n",
      "173/200,train_loss:0.012\n",
      "174/200,train_loss:0.017\n",
      "175/200,train_loss:0.021\n",
      "176/200,train_loss:0.029\n",
      "177/200,train_loss:0.021\n",
      "178/200,train_loss:0.011\n",
      "179/200,train_loss:0.014\n",
      "180/200,train_loss:0.015\n",
      "181/200,train_loss:0.032\n",
      "182/200,train_loss:0.014\n",
      "183/200,train_loss:0.013\n",
      "184/200,train_loss:0.024\n",
      "185/200,train_loss:0.016\n",
      "186/200,train_loss:0.014\n",
      "187/200,train_loss:0.023\n",
      "188/200,train_loss:0.010\n",
      "189/200,train_loss:0.021\n",
      "190/200,train_loss:0.011\n",
      "191/200,train_loss:0.014\n",
      "192/200,train_loss:0.019\n",
      "193/200,train_loss:0.014\n",
      "194/200,train_loss:0.012\n",
      "195/200,train_loss:0.015\n",
      "196/200,train_loss:0.014\n",
      "197/200,train_loss:0.012\n",
      "198/200,train_loss:0.011\n",
      "199/200,train_loss:0.014\n",
      "200/200,train_loss:0.012\n",
      "epoch 3 loss:3.745\n",
      "Epoch 4/19\n",
      "----------\n",
      "1/200,train_loss:0.010\n",
      "2/200,train_loss:0.009\n",
      "3/200,train_loss:0.010\n",
      "4/200,train_loss:0.013\n",
      "5/200,train_loss:0.012\n",
      "6/200,train_loss:0.017\n",
      "7/200,train_loss:0.010\n",
      "8/200,train_loss:0.011\n",
      "9/200,train_loss:0.010\n",
      "10/200,train_loss:0.029\n",
      "11/200,train_loss:0.012\n",
      "12/200,train_loss:0.008\n",
      "13/200,train_loss:0.009\n",
      "14/200,train_loss:0.014\n",
      "15/200,train_loss:0.016\n",
      "16/200,train_loss:0.026\n",
      "17/200,train_loss:0.010\n",
      "18/200,train_loss:0.015\n",
      "19/200,train_loss:0.015\n",
      "20/200,train_loss:0.013\n",
      "21/200,train_loss:0.010\n",
      "22/200,train_loss:0.011\n",
      "23/200,train_loss:0.014\n",
      "24/200,train_loss:0.014\n",
      "25/200,train_loss:0.008\n",
      "26/200,train_loss:0.010\n",
      "27/200,train_loss:0.011\n",
      "28/200,train_loss:0.012\n",
      "29/200,train_loss:0.009\n",
      "30/200,train_loss:0.007\n",
      "31/200,train_loss:0.019\n",
      "32/200,train_loss:0.008\n",
      "33/200,train_loss:0.008\n",
      "34/200,train_loss:0.015\n",
      "35/200,train_loss:0.008\n",
      "36/200,train_loss:0.008\n",
      "37/200,train_loss:0.009\n",
      "38/200,train_loss:0.013\n",
      "39/200,train_loss:0.013\n",
      "40/200,train_loss:0.009\n",
      "41/200,train_loss:0.012\n",
      "42/200,train_loss:0.012\n",
      "43/200,train_loss:0.010\n",
      "44/200,train_loss:0.012\n",
      "45/200,train_loss:0.009\n",
      "46/200,train_loss:0.008\n",
      "47/200,train_loss:0.011\n",
      "48/200,train_loss:0.011\n",
      "49/200,train_loss:0.007\n",
      "50/200,train_loss:0.011\n",
      "51/200,train_loss:0.008\n",
      "52/200,train_loss:0.009\n",
      "53/200,train_loss:0.013\n",
      "54/200,train_loss:0.017\n",
      "55/200,train_loss:0.011\n",
      "56/200,train_loss:0.009\n",
      "57/200,train_loss:0.010\n",
      "58/200,train_loss:0.015\n",
      "59/200,train_loss:0.011\n",
      "60/200,train_loss:0.009\n",
      "61/200,train_loss:0.011\n",
      "62/200,train_loss:0.011\n",
      "63/200,train_loss:0.012\n",
      "64/200,train_loss:0.009\n",
      "65/200,train_loss:0.011\n",
      "66/200,train_loss:0.012\n",
      "67/200,train_loss:0.009\n",
      "68/200,train_loss:0.025\n",
      "69/200,train_loss:0.013\n",
      "70/200,train_loss:0.017\n",
      "71/200,train_loss:0.017\n",
      "72/200,train_loss:0.025\n",
      "73/200,train_loss:0.022\n",
      "74/200,train_loss:0.012\n",
      "75/200,train_loss:0.009\n",
      "76/200,train_loss:0.015\n",
      "77/200,train_loss:0.018\n",
      "78/200,train_loss:0.011\n",
      "79/200,train_loss:0.008\n",
      "80/200,train_loss:0.009\n",
      "81/200,train_loss:0.011\n",
      "82/200,train_loss:0.015\n",
      "83/200,train_loss:0.011\n",
      "84/200,train_loss:0.014\n",
      "85/200,train_loss:0.019\n",
      "86/200,train_loss:0.018\n",
      "87/200,train_loss:0.009\n",
      "88/200,train_loss:0.007\n",
      "89/200,train_loss:0.015\n",
      "90/200,train_loss:0.008\n",
      "91/200,train_loss:0.006\n",
      "92/200,train_loss:0.011\n",
      "93/200,train_loss:0.010\n",
      "94/200,train_loss:0.013\n",
      "95/200,train_loss:0.014\n",
      "96/200,train_loss:0.027\n",
      "97/200,train_loss:0.010\n",
      "98/200,train_loss:0.016\n",
      "99/200,train_loss:0.011\n",
      "100/200,train_loss:0.018\n",
      "101/200,train_loss:0.020\n",
      "102/200,train_loss:0.012\n",
      "103/200,train_loss:0.010\n",
      "104/200,train_loss:0.015\n",
      "105/200,train_loss:0.014\n",
      "106/200,train_loss:0.022\n",
      "107/200,train_loss:0.017\n",
      "108/200,train_loss:0.015\n",
      "109/200,train_loss:0.027\n",
      "110/200,train_loss:0.028\n",
      "111/200,train_loss:0.036\n",
      "112/200,train_loss:0.014\n",
      "113/200,train_loss:0.015\n",
      "114/200,train_loss:0.015\n",
      "115/200,train_loss:0.024\n",
      "116/200,train_loss:0.023\n",
      "117/200,train_loss:0.020\n",
      "118/200,train_loss:0.018\n",
      "119/200,train_loss:0.012\n",
      "120/200,train_loss:0.014\n",
      "121/200,train_loss:0.008\n",
      "122/200,train_loss:0.008\n",
      "123/200,train_loss:0.023\n",
      "124/200,train_loss:0.025\n",
      "125/200,train_loss:0.034\n",
      "126/200,train_loss:0.010\n",
      "127/200,train_loss:0.012\n",
      "128/200,train_loss:0.014\n",
      "129/200,train_loss:0.023\n",
      "130/200,train_loss:0.022\n",
      "131/200,train_loss:0.015\n",
      "132/200,train_loss:0.015\n",
      "133/200,train_loss:0.014\n",
      "134/200,train_loss:0.013\n",
      "135/200,train_loss:0.009\n",
      "136/200,train_loss:0.014\n",
      "137/200,train_loss:0.015\n",
      "138/200,train_loss:0.018\n",
      "139/200,train_loss:0.018\n",
      "140/200,train_loss:0.026\n",
      "141/200,train_loss:0.013\n",
      "142/200,train_loss:0.010\n",
      "143/200,train_loss:0.008\n",
      "144/200,train_loss:0.014\n",
      "145/200,train_loss:0.010\n",
      "146/200,train_loss:0.017\n",
      "147/200,train_loss:0.010\n",
      "148/200,train_loss:0.007\n",
      "149/200,train_loss:0.012\n",
      "150/200,train_loss:0.009\n",
      "151/200,train_loss:0.009\n",
      "152/200,train_loss:0.007\n",
      "153/200,train_loss:0.008\n",
      "154/200,train_loss:0.014\n",
      "155/200,train_loss:0.016\n",
      "156/200,train_loss:0.010\n",
      "157/200,train_loss:0.017\n",
      "158/200,train_loss:0.010\n",
      "159/200,train_loss:0.022\n",
      "160/200,train_loss:0.019\n",
      "161/200,train_loss:0.016\n",
      "162/200,train_loss:0.010\n",
      "163/200,train_loss:0.018\n",
      "164/200,train_loss:0.008\n",
      "165/200,train_loss:0.012\n",
      "166/200,train_loss:0.011\n",
      "167/200,train_loss:0.012\n",
      "168/200,train_loss:0.009\n",
      "169/200,train_loss:0.005\n",
      "170/200,train_loss:0.010\n",
      "171/200,train_loss:0.008\n",
      "172/200,train_loss:0.016\n",
      "173/200,train_loss:0.012\n",
      "174/200,train_loss:0.008\n",
      "175/200,train_loss:0.009\n",
      "176/200,train_loss:0.009\n",
      "177/200,train_loss:0.011\n",
      "178/200,train_loss:0.008\n",
      "179/200,train_loss:0.012\n",
      "180/200,train_loss:0.011\n",
      "181/200,train_loss:0.007\n",
      "182/200,train_loss:0.011\n",
      "183/200,train_loss:0.010\n",
      "184/200,train_loss:0.005\n",
      "185/200,train_loss:0.024\n",
      "186/200,train_loss:0.010\n",
      "187/200,train_loss:0.010\n",
      "188/200,train_loss:0.016\n",
      "189/200,train_loss:0.011\n",
      "190/200,train_loss:0.008\n",
      "191/200,train_loss:0.016\n",
      "192/200,train_loss:0.012\n",
      "193/200,train_loss:0.011\n",
      "194/200,train_loss:0.011\n",
      "195/200,train_loss:0.008\n",
      "196/200,train_loss:0.010\n",
      "197/200,train_loss:0.013\n",
      "198/200,train_loss:0.009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/200,train_loss:0.010\n",
      "200/200,train_loss:0.043\n",
      "epoch 4 loss:2.662\n",
      "Epoch 5/19\n",
      "----------\n",
      "1/200,train_loss:0.016\n",
      "2/200,train_loss:0.017\n",
      "3/200,train_loss:0.014\n",
      "4/200,train_loss:0.013\n",
      "5/200,train_loss:0.017\n",
      "6/200,train_loss:0.015\n",
      "7/200,train_loss:0.012\n",
      "8/200,train_loss:0.015\n",
      "9/200,train_loss:0.026\n",
      "10/200,train_loss:0.016\n",
      "11/200,train_loss:0.021\n",
      "12/200,train_loss:0.010\n",
      "13/200,train_loss:0.011\n",
      "14/200,train_loss:0.011\n",
      "15/200,train_loss:0.009\n",
      "16/200,train_loss:0.017\n",
      "17/200,train_loss:0.016\n",
      "18/200,train_loss:0.012\n",
      "19/200,train_loss:0.015\n",
      "20/200,train_loss:0.012\n",
      "21/200,train_loss:0.010\n",
      "22/200,train_loss:0.008\n",
      "23/200,train_loss:0.006\n",
      "24/200,train_loss:0.008\n",
      "25/200,train_loss:0.008\n",
      "26/200,train_loss:0.014\n",
      "27/200,train_loss:0.017\n",
      "28/200,train_loss:0.012\n",
      "29/200,train_loss:0.009\n",
      "30/200,train_loss:0.012\n",
      "31/200,train_loss:0.011\n",
      "32/200,train_loss:0.012\n",
      "33/200,train_loss:0.012\n",
      "34/200,train_loss:0.013\n",
      "35/200,train_loss:0.009\n",
      "36/200,train_loss:0.009\n",
      "37/200,train_loss:0.004\n",
      "38/200,train_loss:0.012\n",
      "39/200,train_loss:0.009\n",
      "40/200,train_loss:0.017\n",
      "41/200,train_loss:0.009\n",
      "42/200,train_loss:0.007\n",
      "43/200,train_loss:0.005\n",
      "44/200,train_loss:0.023\n",
      "45/200,train_loss:0.009\n",
      "46/200,train_loss:0.013\n",
      "47/200,train_loss:0.008\n",
      "48/200,train_loss:0.008\n",
      "49/200,train_loss:0.010\n",
      "50/200,train_loss:0.014\n",
      "51/200,train_loss:0.017\n",
      "52/200,train_loss:0.005\n",
      "53/200,train_loss:0.005\n",
      "54/200,train_loss:0.017\n",
      "55/200,train_loss:0.015\n",
      "56/200,train_loss:0.006\n",
      "57/200,train_loss:0.009\n",
      "58/200,train_loss:0.007\n",
      "59/200,train_loss:0.010\n",
      "60/200,train_loss:0.008\n",
      "61/200,train_loss:0.013\n",
      "62/200,train_loss:0.005\n",
      "63/200,train_loss:0.010\n",
      "64/200,train_loss:0.008\n",
      "65/200,train_loss:0.009\n",
      "66/200,train_loss:0.011\n",
      "67/200,train_loss:0.008\n",
      "68/200,train_loss:0.008\n",
      "69/200,train_loss:0.007\n",
      "70/200,train_loss:0.006\n",
      "71/200,train_loss:0.010\n",
      "72/200,train_loss:0.010\n",
      "73/200,train_loss:0.006\n",
      "74/200,train_loss:0.006\n",
      "75/200,train_loss:0.017\n",
      "76/200,train_loss:0.006\n",
      "77/200,train_loss:0.006\n",
      "78/200,train_loss:0.013\n",
      "79/200,train_loss:0.011\n",
      "80/200,train_loss:0.006\n",
      "81/200,train_loss:0.008\n",
      "82/200,train_loss:0.005\n",
      "83/200,train_loss:0.011\n",
      "84/200,train_loss:0.004\n",
      "85/200,train_loss:0.008\n",
      "86/200,train_loss:0.006\n",
      "87/200,train_loss:0.010\n",
      "88/200,train_loss:0.014\n",
      "89/200,train_loss:0.005\n",
      "90/200,train_loss:0.007\n",
      "91/200,train_loss:0.008\n",
      "92/200,train_loss:0.024\n",
      "93/200,train_loss:0.007\n",
      "94/200,train_loss:0.019\n",
      "95/200,train_loss:0.010\n",
      "96/200,train_loss:0.005\n",
      "97/200,train_loss:0.006\n",
      "98/200,train_loss:0.010\n",
      "99/200,train_loss:0.009\n",
      "100/200,train_loss:0.008\n",
      "101/200,train_loss:0.013\n",
      "102/200,train_loss:0.007\n",
      "103/200,train_loss:0.011\n",
      "104/200,train_loss:0.012\n",
      "105/200,train_loss:0.005\n",
      "106/200,train_loss:0.010\n",
      "107/200,train_loss:0.005\n",
      "108/200,train_loss:0.020\n",
      "109/200,train_loss:0.008\n",
      "110/200,train_loss:0.005\n",
      "111/200,train_loss:0.014\n",
      "112/200,train_loss:0.011\n",
      "113/200,train_loss:0.009\n",
      "114/200,train_loss:0.014\n",
      "115/200,train_loss:0.011\n",
      "116/200,train_loss:0.013\n",
      "117/200,train_loss:0.007\n",
      "118/200,train_loss:0.007\n",
      "119/200,train_loss:0.010\n",
      "120/200,train_loss:0.012\n",
      "121/200,train_loss:0.009\n",
      "122/200,train_loss:0.010\n",
      "123/200,train_loss:0.006\n",
      "124/200,train_loss:0.007\n",
      "125/200,train_loss:0.009\n",
      "126/200,train_loss:0.008\n",
      "127/200,train_loss:0.010\n",
      "128/200,train_loss:0.010\n",
      "129/200,train_loss:0.016\n",
      "130/200,train_loss:0.014\n",
      "131/200,train_loss:0.010\n",
      "132/200,train_loss:0.008\n",
      "133/200,train_loss:0.009\n",
      "134/200,train_loss:0.012\n",
      "135/200,train_loss:0.005\n",
      "136/200,train_loss:0.009\n",
      "137/200,train_loss:0.008\n",
      "138/200,train_loss:0.006\n",
      "139/200,train_loss:0.012\n",
      "140/200,train_loss:0.009\n",
      "141/200,train_loss:0.011\n",
      "142/200,train_loss:0.010\n",
      "143/200,train_loss:0.009\n",
      "144/200,train_loss:0.016\n",
      "145/200,train_loss:0.010\n",
      "146/200,train_loss:0.011\n",
      "147/200,train_loss:0.014\n",
      "148/200,train_loss:0.014\n",
      "149/200,train_loss:0.008\n",
      "150/200,train_loss:0.013\n",
      "151/200,train_loss:0.009\n",
      "152/200,train_loss:0.014\n",
      "153/200,train_loss:0.011\n",
      "154/200,train_loss:0.008\n",
      "155/200,train_loss:0.007\n",
      "156/200,train_loss:0.013\n",
      "157/200,train_loss:0.012\n",
      "158/200,train_loss:0.007\n",
      "159/200,train_loss:0.010\n",
      "160/200,train_loss:0.015\n",
      "161/200,train_loss:0.009\n",
      "162/200,train_loss:0.012\n",
      "163/200,train_loss:0.007\n",
      "164/200,train_loss:0.008\n",
      "165/200,train_loss:0.011\n",
      "166/200,train_loss:0.008\n",
      "167/200,train_loss:0.011\n",
      "168/200,train_loss:0.008\n",
      "169/200,train_loss:0.008\n",
      "170/200,train_loss:0.012\n",
      "171/200,train_loss:0.008\n",
      "172/200,train_loss:0.009\n",
      "173/200,train_loss:0.008\n",
      "174/200,train_loss:0.013\n",
      "175/200,train_loss:0.010\n",
      "176/200,train_loss:0.009\n",
      "177/200,train_loss:0.009\n",
      "178/200,train_loss:0.007\n",
      "179/200,train_loss:0.007\n",
      "180/200,train_loss:0.006\n",
      "181/200,train_loss:0.012\n",
      "182/200,train_loss:0.012\n",
      "183/200,train_loss:0.008\n",
      "184/200,train_loss:0.013\n",
      "185/200,train_loss:0.008\n",
      "186/200,train_loss:0.007\n",
      "187/200,train_loss:0.010\n",
      "188/200,train_loss:0.014\n",
      "189/200,train_loss:0.008\n",
      "190/200,train_loss:0.007\n",
      "191/200,train_loss:0.008\n",
      "192/200,train_loss:0.009\n",
      "193/200,train_loss:0.007\n",
      "194/200,train_loss:0.005\n",
      "195/200,train_loss:0.005\n",
      "196/200,train_loss:0.010\n",
      "197/200,train_loss:0.012\n",
      "198/200,train_loss:0.009\n",
      "199/200,train_loss:0.007\n",
      "200/200,train_loss:0.011\n",
      "epoch 5 loss:2.047\n",
      "Epoch 6/19\n",
      "----------\n",
      "1/200,train_loss:0.004\n",
      "2/200,train_loss:0.009\n",
      "3/200,train_loss:0.006\n",
      "4/200,train_loss:0.010\n",
      "5/200,train_loss:0.011\n",
      "6/200,train_loss:0.007\n",
      "7/200,train_loss:0.009\n",
      "8/200,train_loss:0.005\n",
      "9/200,train_loss:0.010\n",
      "10/200,train_loss:0.008\n",
      "11/200,train_loss:0.008\n",
      "12/200,train_loss:0.008\n",
      "13/200,train_loss:0.012\n",
      "14/200,train_loss:0.010\n",
      "15/200,train_loss:0.011\n",
      "16/200,train_loss:0.007\n",
      "17/200,train_loss:0.007\n",
      "18/200,train_loss:0.008\n",
      "19/200,train_loss:0.011\n",
      "20/200,train_loss:0.010\n",
      "21/200,train_loss:0.010\n",
      "22/200,train_loss:0.011\n",
      "23/200,train_loss:0.013\n",
      "24/200,train_loss:0.007\n",
      "25/200,train_loss:0.007\n",
      "26/200,train_loss:0.010\n",
      "27/200,train_loss:0.009\n",
      "28/200,train_loss:0.006\n",
      "29/200,train_loss:0.004\n",
      "30/200,train_loss:0.007\n",
      "31/200,train_loss:0.009\n",
      "32/200,train_loss:0.010\n",
      "33/200,train_loss:0.007\n",
      "34/200,train_loss:0.006\n",
      "35/200,train_loss:0.007\n",
      "36/200,train_loss:0.010\n",
      "37/200,train_loss:0.007\n",
      "38/200,train_loss:0.013\n",
      "39/200,train_loss:0.012\n",
      "40/200,train_loss:0.009\n",
      "41/200,train_loss:0.007\n",
      "42/200,train_loss:0.007\n",
      "43/200,train_loss:0.008\n",
      "44/200,train_loss:0.007\n",
      "45/200,train_loss:0.013\n",
      "46/200,train_loss:0.004\n",
      "47/200,train_loss:0.007\n",
      "48/200,train_loss:0.020\n",
      "49/200,train_loss:0.009\n",
      "50/200,train_loss:0.011\n",
      "51/200,train_loss:0.011\n",
      "52/200,train_loss:0.012\n",
      "53/200,train_loss:0.010\n",
      "54/200,train_loss:0.012\n",
      "55/200,train_loss:0.008\n",
      "56/200,train_loss:0.009\n",
      "57/200,train_loss:0.018\n",
      "58/200,train_loss:0.008\n",
      "59/200,train_loss:0.015\n",
      "60/200,train_loss:0.006\n",
      "61/200,train_loss:0.009\n",
      "62/200,train_loss:0.010\n",
      "63/200,train_loss:0.012\n",
      "64/200,train_loss:0.008\n",
      "65/200,train_loss:0.007\n",
      "66/200,train_loss:0.006\n",
      "67/200,train_loss:0.008\n",
      "68/200,train_loss:0.008\n",
      "69/200,train_loss:0.009\n",
      "70/200,train_loss:0.011\n",
      "71/200,train_loss:0.012\n",
      "72/200,train_loss:0.018\n",
      "73/200,train_loss:0.006\n",
      "74/200,train_loss:0.015\n",
      "75/200,train_loss:0.008\n",
      "76/200,train_loss:0.010\n",
      "77/200,train_loss:0.011\n",
      "78/200,train_loss:0.010\n",
      "79/200,train_loss:0.012\n",
      "80/200,train_loss:0.012\n",
      "81/200,train_loss:0.007\n",
      "82/200,train_loss:0.007\n",
      "83/200,train_loss:0.011\n",
      "84/200,train_loss:0.017\n",
      "85/200,train_loss:0.009\n",
      "86/200,train_loss:0.008\n",
      "87/200,train_loss:0.008\n",
      "88/200,train_loss:0.007\n",
      "89/200,train_loss:0.011\n",
      "90/200,train_loss:0.010\n",
      "91/200,train_loss:0.009\n",
      "92/200,train_loss:0.004\n",
      "93/200,train_loss:0.010\n",
      "94/200,train_loss:0.019\n",
      "95/200,train_loss:0.011\n",
      "96/200,train_loss:0.011\n",
      "97/200,train_loss:0.021\n",
      "98/200,train_loss:0.011\n",
      "99/200,train_loss:0.015\n",
      "100/200,train_loss:0.015\n",
      "101/200,train_loss:0.013\n",
      "102/200,train_loss:0.014\n",
      "103/200,train_loss:0.018\n",
      "104/200,train_loss:0.012\n",
      "105/200,train_loss:0.017\n",
      "106/200,train_loss:0.007\n",
      "107/200,train_loss:0.012\n",
      "108/200,train_loss:0.014\n",
      "109/200,train_loss:0.015\n",
      "110/200,train_loss:0.013\n",
      "111/200,train_loss:0.016\n",
      "112/200,train_loss:0.009\n",
      "113/200,train_loss:0.011\n",
      "114/200,train_loss:0.008\n",
      "115/200,train_loss:0.007\n",
      "116/200,train_loss:0.019\n",
      "117/200,train_loss:0.007\n",
      "118/200,train_loss:0.010\n",
      "119/200,train_loss:0.011\n",
      "120/200,train_loss:0.010\n",
      "121/200,train_loss:0.012\n",
      "122/200,train_loss:0.010\n",
      "123/200,train_loss:0.015\n",
      "124/200,train_loss:0.012\n",
      "125/200,train_loss:0.009\n",
      "126/200,train_loss:0.006\n",
      "127/200,train_loss:0.007\n",
      "128/200,train_loss:0.007\n",
      "129/200,train_loss:0.009\n",
      "130/200,train_loss:0.008\n",
      "131/200,train_loss:0.010\n",
      "132/200,train_loss:0.028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/200,train_loss:0.010\n",
      "134/200,train_loss:0.009\n",
      "135/200,train_loss:0.012\n",
      "136/200,train_loss:0.008\n",
      "137/200,train_loss:0.012\n",
      "138/200,train_loss:0.013\n",
      "139/200,train_loss:0.019\n",
      "140/200,train_loss:0.009\n",
      "141/200,train_loss:0.015\n",
      "142/200,train_loss:0.009\n",
      "143/200,train_loss:0.011\n",
      "144/200,train_loss:0.013\n",
      "145/200,train_loss:0.012\n",
      "146/200,train_loss:0.010\n",
      "147/200,train_loss:0.009\n",
      "148/200,train_loss:0.010\n",
      "149/200,train_loss:0.010\n",
      "150/200,train_loss:0.009\n",
      "151/200,train_loss:0.008\n",
      "152/200,train_loss:0.007\n",
      "153/200,train_loss:0.006\n",
      "154/200,train_loss:0.016\n",
      "155/200,train_loss:0.008\n",
      "156/200,train_loss:0.009\n",
      "157/200,train_loss:0.017\n",
      "158/200,train_loss:0.013\n",
      "159/200,train_loss:0.011\n",
      "160/200,train_loss:0.009\n",
      "161/200,train_loss:0.010\n",
      "162/200,train_loss:0.010\n",
      "163/200,train_loss:0.014\n",
      "164/200,train_loss:0.013\n",
      "165/200,train_loss:0.009\n",
      "166/200,train_loss:0.012\n",
      "167/200,train_loss:0.008\n",
      "168/200,train_loss:0.008\n",
      "169/200,train_loss:0.006\n",
      "170/200,train_loss:0.009\n",
      "171/200,train_loss:0.015\n",
      "172/200,train_loss:0.007\n",
      "173/200,train_loss:0.010\n",
      "174/200,train_loss:0.010\n",
      "175/200,train_loss:0.006\n",
      "176/200,train_loss:0.007\n",
      "177/200,train_loss:0.010\n",
      "178/200,train_loss:0.005\n",
      "179/200,train_loss:0.019\n",
      "180/200,train_loss:0.008\n",
      "181/200,train_loss:0.010\n",
      "182/200,train_loss:0.009\n",
      "183/200,train_loss:0.009\n",
      "184/200,train_loss:0.008\n",
      "185/200,train_loss:0.008\n",
      "186/200,train_loss:0.007\n",
      "187/200,train_loss:0.011\n",
      "188/200,train_loss:0.010\n",
      "189/200,train_loss:0.006\n",
      "190/200,train_loss:0.008\n",
      "191/200,train_loss:0.007\n",
      "192/200,train_loss:0.011\n",
      "193/200,train_loss:0.007\n",
      "194/200,train_loss:0.008\n",
      "195/200,train_loss:0.004\n",
      "196/200,train_loss:0.006\n",
      "197/200,train_loss:0.007\n",
      "198/200,train_loss:0.008\n",
      "199/200,train_loss:0.010\n",
      "200/200,train_loss:0.010\n",
      "epoch 6 loss:2.009\n",
      "Epoch 7/19\n",
      "----------\n",
      "1/200,train_loss:0.005\n",
      "2/200,train_loss:0.006\n",
      "3/200,train_loss:0.008\n",
      "4/200,train_loss:0.006\n",
      "5/200,train_loss:0.008\n",
      "6/200,train_loss:0.010\n",
      "7/200,train_loss:0.013\n",
      "8/200,train_loss:0.005\n",
      "9/200,train_loss:0.008\n",
      "10/200,train_loss:0.005\n",
      "11/200,train_loss:0.009\n",
      "12/200,train_loss:0.012\n",
      "13/200,train_loss:0.008\n",
      "14/200,train_loss:0.006\n",
      "15/200,train_loss:0.010\n",
      "16/200,train_loss:0.006\n",
      "17/200,train_loss:0.008\n",
      "18/200,train_loss:0.013\n",
      "19/200,train_loss:0.009\n",
      "20/200,train_loss:0.009\n",
      "21/200,train_loss:0.009\n",
      "22/200,train_loss:0.007\n",
      "23/200,train_loss:0.009\n",
      "24/200,train_loss:0.011\n",
      "25/200,train_loss:0.013\n",
      "26/200,train_loss:0.007\n",
      "27/200,train_loss:0.008\n",
      "28/200,train_loss:0.012\n",
      "29/200,train_loss:0.008\n",
      "30/200,train_loss:0.007\n",
      "31/200,train_loss:0.007\n",
      "32/200,train_loss:0.009\n",
      "33/200,train_loss:0.008\n",
      "34/200,train_loss:0.007\n",
      "35/200,train_loss:0.007\n",
      "36/200,train_loss:0.006\n",
      "37/200,train_loss:0.010\n",
      "38/200,train_loss:0.006\n",
      "39/200,train_loss:0.012\n",
      "40/200,train_loss:0.012\n",
      "41/200,train_loss:0.006\n",
      "42/200,train_loss:0.007\n",
      "43/200,train_loss:0.013\n",
      "44/200,train_loss:0.006\n",
      "45/200,train_loss:0.005\n",
      "46/200,train_loss:0.009\n",
      "47/200,train_loss:0.007\n",
      "48/200,train_loss:0.007\n",
      "49/200,train_loss:0.007\n",
      "50/200,train_loss:0.010\n",
      "51/200,train_loss:0.012\n",
      "52/200,train_loss:0.007\n",
      "53/200,train_loss:0.015\n",
      "54/200,train_loss:0.010\n",
      "55/200,train_loss:0.008\n",
      "56/200,train_loss:0.006\n",
      "57/200,train_loss:0.006\n",
      "58/200,train_loss:0.009\n",
      "59/200,train_loss:0.007\n",
      "60/200,train_loss:0.004\n",
      "61/200,train_loss:0.006\n",
      "62/200,train_loss:0.004\n",
      "63/200,train_loss:0.008\n",
      "64/200,train_loss:0.009\n",
      "65/200,train_loss:0.014\n",
      "66/200,train_loss:0.010\n",
      "67/200,train_loss:0.009\n",
      "68/200,train_loss:0.006\n",
      "69/200,train_loss:0.012\n",
      "70/200,train_loss:0.008\n",
      "71/200,train_loss:0.009\n",
      "72/200,train_loss:0.008\n",
      "73/200,train_loss:0.011\n",
      "74/200,train_loss:0.007\n",
      "75/200,train_loss:0.012\n",
      "76/200,train_loss:0.009\n",
      "77/200,train_loss:0.008\n",
      "78/200,train_loss:0.006\n",
      "79/200,train_loss:0.012\n",
      "80/200,train_loss:0.005\n",
      "81/200,train_loss:0.009\n",
      "82/200,train_loss:0.005\n",
      "83/200,train_loss:0.007\n",
      "84/200,train_loss:0.008\n",
      "85/200,train_loss:0.005\n",
      "86/200,train_loss:0.011\n",
      "87/200,train_loss:0.005\n",
      "88/200,train_loss:0.008\n",
      "89/200,train_loss:0.008\n",
      "90/200,train_loss:0.010\n",
      "91/200,train_loss:0.006\n",
      "92/200,train_loss:0.005\n",
      "93/200,train_loss:0.009\n",
      "94/200,train_loss:0.011\n",
      "95/200,train_loss:0.006\n",
      "96/200,train_loss:0.011\n",
      "97/200,train_loss:0.008\n",
      "98/200,train_loss:0.010\n",
      "99/200,train_loss:0.008\n",
      "100/200,train_loss:0.009\n",
      "101/200,train_loss:0.009\n",
      "102/200,train_loss:0.007\n",
      "103/200,train_loss:0.006\n",
      "104/200,train_loss:0.007\n",
      "105/200,train_loss:0.005\n",
      "106/200,train_loss:0.005\n",
      "107/200,train_loss:0.017\n",
      "108/200,train_loss:0.010\n",
      "109/200,train_loss:0.003\n",
      "110/200,train_loss:0.005\n",
      "111/200,train_loss:0.013\n",
      "112/200,train_loss:0.010\n",
      "113/200,train_loss:0.012\n",
      "114/200,train_loss:0.012\n",
      "115/200,train_loss:0.007\n",
      "116/200,train_loss:0.011\n",
      "117/200,train_loss:0.006\n",
      "118/200,train_loss:0.008\n",
      "119/200,train_loss:0.005\n",
      "120/200,train_loss:0.008\n",
      "121/200,train_loss:0.009\n",
      "122/200,train_loss:0.009\n",
      "123/200,train_loss:0.010\n",
      "124/200,train_loss:0.007\n",
      "125/200,train_loss:0.006\n",
      "126/200,train_loss:0.006\n",
      "127/200,train_loss:0.011\n",
      "128/200,train_loss:0.006\n",
      "129/200,train_loss:0.006\n",
      "130/200,train_loss:0.011\n",
      "131/200,train_loss:0.009\n",
      "132/200,train_loss:0.006\n",
      "133/200,train_loss:0.006\n",
      "134/200,train_loss:0.013\n",
      "135/200,train_loss:0.009\n",
      "136/200,train_loss:0.004\n",
      "137/200,train_loss:0.008\n",
      "138/200,train_loss:0.008\n",
      "139/200,train_loss:0.008\n",
      "140/200,train_loss:0.008\n",
      "141/200,train_loss:0.004\n",
      "142/200,train_loss:0.006\n",
      "143/200,train_loss:0.007\n",
      "144/200,train_loss:0.007\n",
      "145/200,train_loss:0.009\n",
      "146/200,train_loss:0.006\n",
      "147/200,train_loss:0.008\n",
      "148/200,train_loss:0.009\n",
      "149/200,train_loss:0.006\n",
      "150/200,train_loss:0.008\n",
      "151/200,train_loss:0.008\n",
      "152/200,train_loss:0.007\n",
      "153/200,train_loss:0.006\n",
      "154/200,train_loss:0.012\n",
      "155/200,train_loss:0.011\n",
      "156/200,train_loss:0.007\n",
      "157/200,train_loss:0.006\n",
      "158/200,train_loss:0.010\n",
      "159/200,train_loss:0.004\n",
      "160/200,train_loss:0.007\n",
      "161/200,train_loss:0.007\n",
      "162/200,train_loss:0.010\n",
      "163/200,train_loss:0.009\n",
      "164/200,train_loss:0.010\n",
      "165/200,train_loss:0.008\n",
      "166/200,train_loss:0.007\n",
      "167/200,train_loss:0.008\n",
      "168/200,train_loss:0.007\n",
      "169/200,train_loss:0.006\n",
      "170/200,train_loss:0.005\n",
      "171/200,train_loss:0.007\n",
      "172/200,train_loss:0.004\n",
      "173/200,train_loss:0.006\n",
      "174/200,train_loss:0.004\n",
      "175/200,train_loss:0.006\n",
      "176/200,train_loss:0.007\n",
      "177/200,train_loss:0.006\n",
      "178/200,train_loss:0.005\n",
      "179/200,train_loss:0.006\n",
      "180/200,train_loss:0.005\n",
      "181/200,train_loss:0.004\n",
      "182/200,train_loss:0.005\n",
      "183/200,train_loss:0.003\n",
      "184/200,train_loss:0.004\n",
      "185/200,train_loss:0.005\n",
      "186/200,train_loss:0.008\n",
      "187/200,train_loss:0.005\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-5604df5decb6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-74e69141e9fd>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(batch_size)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mliver_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLiverDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"E:\\\\BaiduNetdiskDownload\\\\u_net_liver-master\\\\data\\\\train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_transforms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_transforms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mdataloaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mliver_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-74e69141e9fd>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, dataload, num_epochs)\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[1;31m# forward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Pyenv\\ml3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-1171c22bdc69>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mc1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mp1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[0mc2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mp2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Pyenv\\ml3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Pyenv\\ml3\\lib\\site-packages\\torch\\nn\\modules\\pooling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[0;32m    140\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m                             self.return_indices)\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Pyenv\\ml3\\lib\\site-packages\\torch\\_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Pyenv\\ml3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    537\u001b[0m         \u001b[0mstride\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m     return torch.max_pool2d(\n\u001b[1;32m--> 539\u001b[1;33m         input, kernel_size, stride, padding, dilation, ceil_mode)\n\u001b[0m\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m max_pool2d = boolean_dispatch(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coupled-survey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test()\n",
    "model_dir = \"\"\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
